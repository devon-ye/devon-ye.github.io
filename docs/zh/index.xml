<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Devean</title>
    <link>https://www.devean.cn/zh/</link>
    <description>Recent content on Devean</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Fri, 01 Mar 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.devean.cn/zh/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>如何设计低延迟、高可用、高并发的交易服务技术方案</title>
      <link>https://www.devean.cn/zh/blog/2024/qptrade/</link>
      <pubDate>Fri, 01 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2024/qptrade/</guid>
      <description>承兑服务技术方案要点 需求背景 现状： BTC、ETH简选期权只能以BTC或ETH下单，而不能以稳定币USDT下单。 功能需求 用户以USDT稳定币直接下单开仓期权。 期权平仓后将BTC、ETH直接兑换为USDT划入用户账户。 非功能性需求 低延迟(依赖交易服务市场撮合、故延迟越高、行情变化可能导致系统账户产生资损) 高可用 (即服务不可宕机、升级发布尽可能不停机，重启部署可自动完全恢复) 高并发（即交易行情到来时、多用户并发操作、用户间是并发的，不能排队处理） 业务流程 用户在页面操作简选期权下单以USDT下单模式下单BTC简选期权。 柜台报价接口传入BTC期权张数，柜台服务加上价差后调用资金账户返回所需USDT数量。 用户下单BTC开仓期权张数,柜台以资金账户报价、扣除用户账户USDT,给用户开仓BTC简选期权，用户端开仓成功。 服务端，柜台将BTC期权开仓订单记录以异步的方式同步给承兑服务、承兑服务完成后续的交易服务平账操作。 i. 承兑服务调用柜台服务接口完成换币系统账户加USDT、减BTC的操作。 ii. 承兑服务调用资金服务完成系统账户到资金账户的USDT划转。 iii. 承兑服务调用交易服务接口完成USDT换BTC的操作。 iv. 承兑服服务调用资金账户将换回的BTC划转值系统账户。 技术难点 从柜台服务库夸系统低延迟交易订单同步至承兑服务后不丢、不重，Canal、Kafka中间件集群异常需要容错处理。 柜台服务从用户账户完成减USDT、开仓BTC期权动作后,完成用户端交互。而承兑服务需要在极低延迟时间内需要完成后续平账的操作，因换币依赖于市场行情，延迟越高存在差价滑点的概率越高。 承兑服务要完成平账操作,保证以下4次接口调用顺序性依赖、且多用户执行时多用户间并发性。 i. 承兑服务调用柜台服务接口完成换币系统账户加USDT、减BTC的操作。 ii. 承兑服务调用资金服务完成系统账户到资金账户的USDT划转。 iii. 承兑服务调用交易服务接口完成USDT换BTC的操作。 iv. 承兑服服务调用资金账户将换回的BTC划转值系统账户。 服务迭代或异常重启部署、中间态的订单依旧可恢复完成剩余步骤，完成换币动作。 为了避免正常停机导致订单延迟过高产生资损,服务升级需要不停机。 解决方案 柜台服务到承兑服务订单低延迟、高可用同步 柜台服务加同步订单表、配置canal表同步，将该表同步写入kafka 承兑服务消费topic后解析Binlog、过滤非换币订单、将订单写入承兑服务同步订单表，以订单唯一id幂等校验。 承兑服务入库后提交offset。随后将该订单放入Disruptor内存队列。 服务启动后会启动定时任务，加载当前订单表每个shard最后一条记录的毫秒级时间戳、缓存每个分片的最后一条记录的时间戳。Map&amp;lt;shardId,timestamp&amp;gt;。 新消费订单记录写入Disruptor内存队列后，会将该记录的时间戳与缓存的时间戳比较，如果大于缓存的时间戳，更新缓存的时间戳。 定时任务每隔3秒检查一次，去查询柜台服务同步订单表,是否存在延迟或未同步订单直接以接口拉取最新为同步订单 状态机架构模式换成低延迟、高并发、高可靠平账流程 实现四个顺序依赖的接口完全异步、多线程并发执行，即基于Disruptor的EventHandler、WorkHandler两个接口实现多线程异步执行。 配置多层多步线程 @Configuration public class DisruptorAutoConfiguration { @Autowired private BizExceptionHandler bizExceptionHandler; public final Integer RING_BUFFER_SIZE = 1024 * 2; public final Integer CORE_SIZE = Runtime.</description>
    </item>
    <item>
      <title>GRPC服务发现方案</title>
      <link>https://www.devean.cn/zh/blog/2024/grpc-service-discovery-solution/</link>
      <pubDate>Sun, 11 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2024/grpc-service-discovery-solution/</guid>
      <description>基于GRPC、spring-boot、zookeeper实现轻量化服务发现&#xA;GRPC服务发现方案 背景 目前服务配置复杂、且测试环境要保证端口不重复 server端做自动扩缩容后,client端无法消费最新的server,需要重启client端 新server服务需要在调用它的client端做大量配置 目前grpc服务心跳也无法生效，需要手动在每个server端服务端添加心跳接口实现 目前服务负载均衡基于AWS的DNS建立长链接,无法均衡 核心痛点 server服务自动扩缩容，需要重启client才能生效 服务化配置复杂，容易配置错误主机信息 需求 功能性需求 现阶段&#xA;服务发现 服务扩缩容后，可在client端实时更新，无需重启服务 服务健康检查 服务出现踢出重连 简化rpc服务配置 后期&#xA;权限控制 灰度路由 服务治理 服务预热 非功能性需求 高可用且 可拓展，具备后期拓展权限控制、限流、熔断、服务预热等治理 方案设计 服务注册流程 grpc-server启动服务注册流程 服务发现流程 具体方案 DB存储方案 DB 存储结构 cluster_name server_name own_address heat_beat instance_hash default user-center host:port timestamp 集群名+服务名+主机端口的hash 方案描述 server端启动后将服务信息写入表，并周期更新心跳, 服务启动时加载shutdownhook钩子函数,服务关闭时删除服务当前实例服务信息 client端调启动时加载服务信息列表并创建rpc链接 client端添加定时任务，根据服务名扫描服务实例信息，并做合并 优点 实现简单 维护成本低 缺点 无法实现强一致性 延迟高 后期拓展接口粒度服务注册时，不易拓展 zk存储方案 zk存储结构 方案描述 1./grpc-clusterName /serverName为实体节点 配置不同的clusterName来区分不同环境 2.主机信息节点为虚节点，以zk心跳来做服务心跳 3.grpc_client端监听serverName节点的子节点事件，处理服务上线下 4.主机节点包含主机写入时间戳 优点 低延迟 强一致 后期拓展接口粒度服务注册时，易于拓展 缺点 维护成本高 存储方案对比 DB redis zookeeper etcd Eureka Consul Nacos 一致性 弱 弱 CP CP AP CP CP+AP 健康检查 不支持 不支持 支持 支持 支持 支持 双向心跳 watcher支持 不支持 不支持 多次注册 一次注册 支持 支持 支持 自动注销 不支持 不支持 支持 支持 需调用其API或超过延迟时间下线 支持 支持 最少节点数 1 3 3 1 3 3 社区 活跃 活跃 不活跃 活跃 活跃 延迟 高 较高 低 低 较高 低 低 拓展接口注册 难度大 容易 容易 容易 容易 容易 难 语言 C++ C++ Java go Java go Java 缺点 可靠性低 当服务达到一定规模是,写入性能存在瓶颈 备注 依赖SDK 依赖SDK 与Registrator结合实现服务发现预注册 eureka1.</description>
    </item>
    <item>
      <title>全链路追踪</title>
      <link>https://www.devean.cn/zh/blog/2024/distributed-tracing/</link>
      <pubDate>Fri, 09 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2024/distributed-tracing/</guid>
      <description>分布式追踪 什么是分布式追踪？ 分布式追踪也叫分布式请求跟踪，是一种针对分布式服务概要分析和监控的方法，特别对于故障发生未知及性能下降原因&#xA;核心概念 traceId:标识一次用户请求生成的唯一ID spanId:标识本次调用在调用链中的位置 为什么需要分布式追踪？ 随着业务量增长，单体服务已经无法满足需求，因此SOA服务化和微服务，且每个服务多实例部署，导致排查故障及性能问题的难度加大&#xA;我们能用分布式追踪能做什么？ 故障定位 跨系统全链路日志聚合 跨系统全链路性能分析 服务依赖拓扑图查看 分布式追踪的实现原理 夸线程:ThreadLocal传递traceId等信息 跨进程:通过封装RPC、HTTP、MQ 协议的header传递traceId等信息&#xA;实现方法: 业界中间件SDK封装，在需要的地方手动处理 编译器字节码插装 好处:业务无感知，开箱即用&#xA;GlobalTracing public class GlobalTracing { private static final ThreadLocal&amp;lt;String&amp;gt; TRACE_ID_LOCAL = new ThreadLocal&amp;lt;&amp;gt;(); public static final String TRACE_ID = &amp;#34;trace_id&amp;#34;; private GlobalTracing() { } public static void setTraceId(String traceId) { TRACE_ID_LOCAL.set(traceId); LogUtils.setTraceId(traceId); } public static String getTraceId() { return TRACE_ID_LOCAL.get(); } public static void remove() { TRACE_ID_LOCAL.remove(); } } 跨进程 Grpc Client public class TracingClientInterceptor implements ClientInterceptor { private static final Metadata.</description>
    </item>
    <item>
      <title>神经网络 | 机器学习</title>
      <link>https://www.devean.cn/zh/blog/2024/machine-learning-neural-networks/</link>
      <pubDate>Thu, 11 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2024/machine-learning-neural-networks/</guid>
      <description>机器学习作为人工智能的一个重要分支，在近年来取得了显著的发展。神经网络，作为机器学习中的核心技术之一，已广泛应用于图像识别、语音处理、自然语言处理等领域。本文旨在深入浅出地解析神经网络的基础原理，以及其在各行各业中的应用实例、代码实战。&#xA;神经网络基础 什么是神经网络 神经网络是一种模仿人类大脑结构设计的算法结构，它由大量的节点（或称为“神经元”）相互连接构成。每个神经元可以接收输入，进行处理后输出到其他神经元。这种结构使得神经网络能够处理复杂的数据模式。&#xA;神经网络的工作原理 神经网络的工作可以分为两个主要阶段：前向传播和反向传播。在前向传播阶段，数据从输入层经过隐藏层到输出层，每一层的神经元对数据进行加权求和，再通过激活函数处理。在反向传播阶段，网络通过计算输出误差并将误差反向传播，以此来调整神经元的权重和偏置，不断优化网络性能。&#xA;神经网络的类型 神经网络有多种类型，每种类型都适用于解决特定的问题。以下是一些主要类型的神经网络及其应用：&#xA;卷积神经网络（CNN） 定义和用途：卷积神经网络主要应用于图像处理领域。它们通过模拟生物视觉系统的机制，有效地识别和处理图像数据。 结构特点：CNN主要由卷积层、池化层和全连接层组成。卷积层用于提取图像中的特征，池化层用于降低特征的维度，全连接层则用于分类或回归分析。 循环神经网络（RNN） 定义和用途：循环神经网络特别适用于处理序列数据，如时间序列分析、语音识别等。它们能够考虑到数据之间的时序关系。 结构特点：RNN的核心是它具有记忆功能，可以保存前一时刻的信息，并在当前时刻与新输入共同影响输出。 长短期记忆网络（LSTM） 定义和用途：LSTM是RNN的一种改进型，特别擅长处理长序列数据，广泛用于语言模型和文本生成。 结构特点：LSTM通过引入三个门（输入门、遗忘门、输出门）来控制信息的流动，有效解决了传统RNN的梯度消失问题。 深度信念网络（DBN） 定义和用途：深度信念网络主要用于无监督学习任务，如特征提取和图像识别。 结构特点：DBN由多层受限玻尔兹曼机（RBM）堆叠而成，每层RBM学习数据在不同抽象层次的表示。 生成对抗网络（GAN） 定义和用途：生成对抗网络在图像生成、风格转换等领域表现出色。 结构特点：GAN由两部分组成——生成器和判别器。生成器生成数据，判别器评估数据。两者相互竞争，共同进步。 自编码器（Autoencoder） 定义和用途：自编码器用于数据降维和特征学习，特别适用于图像重构和降噪。 结构特点：自编码器通过一个编码过程将输入压缩成一个低维表示，然后通过一个解码过程重构输出，使其尽可能接近原始输入。 神经网络在现实世界的应用 神经网络技术在许多领域都有着广泛的应用，以下是一些主要应用领域的详细介绍：&#xA;医疗健康 诊断：神经网络被用于诊断各种疾病，如癌症、糖尿病等，通过分析医学图像或患者数据来辅助医生作出更准确的诊断。 药物开发：利用神经网络分析化合物和生物体的相互作用，加速新药的开发过程。 金融服务 风险管理：神经网络用于预测贷款违约风险、识别欺诈行为，帮助金融机构更有效地管理风险。 量化交易：在股票市场，神经网络可以分析大量历史数据，预测市场趋势，为自动化交易系统提供决策支持。 零售和电子商务 个性化推荐：神经网络通过分析消费者的购买历史、搜索习惯和偏好，提供个性化的商品推荐。 库存管理：通过预测销售趋势和季节性需求变化，神经网络帮助零售商优化库存管理。 自动驾驶和交通管理 环境感知：神经网络处理来自车辆传感器的数据，如摄像头、雷达等，以实现对周围环境的感知。 决策制定：在复杂的交通环境中，神经网络帮助自动驾驶车辆做出快速而准确的驾驶决策。 教育和研究 个性化学习：神经网络分析学生的学习习惯和进度，提供个性化的学习资源和辅导。 科学研究：在科学研究领域，神经网络用于数据分析、模式识别，加速科学发现的过程。 娱乐和媒体 内容创作：在音乐、文本和图像创作领域，神经网络能够生成新的创意内容，如作曲、写作或绘画。 游戏开发：在视频游戏中，神经网络用于创建更真实的游戏环境和更智能的非玩家角色（NPC）。 安全和监控 异常检测：神经网络用于识别网络安全威胁，如恶意软件或入侵尝试。 视频监控：在公共安全领域，神经网络帮助分析监控视频，识别可疑行为或事件。 环境和能源 气候模型：神经网络用于模拟和预测气候变化，帮助科学家更好地理解环境变化。 能源优化：在能源行业，神经网络用于预测能源需求，优化能源分配和利用。 代码实战 import tensorflow as tf from tensorflow.keras.datasets import mnist from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D from tensorflow.</description>
    </item>
    <item>
      <title>决策树 | 机器学习</title>
      <link>https://www.devean.cn/zh/blog/2024/machine-learning-decision-trees/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2024/machine-learning-decision-trees/</guid>
      <description>引言 机器学习领域中，决策树是一种强大的算法，被广泛应用于分类和回归问题。本文将深入探讨决策树的概念、原理、流程、工业应用场景，并通过代码实践展示其实现。&#xA;概念 决策树是一种树状模型，用于对实例进行决策。它的结构类似于流程图，其中每个内部节点代表一个特征或属性，每个分支代表一个决策，而每个叶子节点代表一个类别或输出。通过沿着树的分支进行决策，最终到达叶子节点以得到预测结果。针对“今天是否打高尔夫”这个问题决策树推理过程！&#xA;原理 决策树的构建基于信息论的概念。常用的决策树算法包括ID3、C4.5、CART等，它们通过选择最佳的特征进行节点分裂，以最大化信息增益或基尼指数。&#xA;决策树的组成 根节点（Root Node）： 决策树的起点，通常代表整个数据集。 内部节点（Internal Node）： 非叶节点，用于进一步划分数据。 叶节点（Leaf Node）： 决策树的终端节点，每个叶节点代表一个数据类别或预测值。 决策树的生成 特征选择 从训练数据中选出最佳特征作为当前节点的分裂标准。在决策树模型中，我们有三种方式来选取最优特征，包括信息增益、信息增益率和基尼指数。&#xA;信息增益 信息增益是一种用于特征选择的评估标准，它衡量了通过某一特征对数据进行划分后，数据纯度的提高程度。在决策树生成过程中，选择信息增益最大的特征作为当前节点的分裂标准。信息增益的计算公式为：&#xA;$$G(X, A) = H(X) - \sum_{i=1}^{m} \frac{|D_i|}{|D|} H(D_i)$$&#xA;其中：&#xA;$G(X, A)$ 是特征 $A$ 的信息增益； $H(X)$ 是整个数据集的信息熵； $D_i$ 是特征 $A$ 划分后的子数据集； $|D_i|$ 是子数据集的大小； $|D|$ 是整个数据集的大小； $H(D_i)$ 是子数据集 $D_i$ 的信息熵。 信息增益越大，表示选择该特征进行分裂能够带来更大的纯度提升，使得决策更准确。&#xA;信息增益率 增益率是信息增益的一种变体，它对信息增益进行了归一化，解决了信息增益对取值数目较多的特征的偏好问题。增益率的计算公式为：&#xA;$$Gain_Ratio(X, A) = \frac{G(X, A)}{H(A)}$$&#xA;其中：&#xA;$ Gain_Ratio(X, A) $ 是特征 $ A $ 的增益率； $ H(A) $ 是特征 $ A $ 的信息熵。 增益率不仅考虑了信息增益，还考虑了特征本身的信息熵，避免了对取值数目较多的特征的过度偏好。</description>
    </item>
    <item>
      <title>自组织映射 | 机器学习</title>
      <link>https://www.devean.cn/zh/blog/2023/machine-learning-self-organnizing-maps/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/machine-learning-self-organnizing-maps/</guid>
      <description>引言 在机器学习的广阔领域中，自组织映射（Self-Organizing Map，SOM）占据了一席之地。它是一种无监督学习的人工神经网络，用于数据的降维和可视化。今天，我们将深入探讨SOM的概念、定理、原理，并通过Python示例展示其在实际问题中的应用。&#xA;历史背景 SOM的提出源于对大脑皮层处理信息的方式的启发。Kohonen教授通过模拟这种生物学上的信息处理机制，创建了一种能够揭示数据内在结构的神经网络模型。从80年代初到现在，SOM已经在许多领域得到了广泛的应用，如金融分析、生物信息学、图像处理等。&#xA;概念 自组织映射（SOM）是由芬兰教授Teuvo Kohonen在1982年提出的一种无监督学习算法。它通过训练过程自我组织，形成一个拓扑结构，能够将高维数据映射到低维空间（通常是二维），同时保持数据的拓扑关系，这使得它在数据可视化方面特别有用。&#xA;与其他机器学习技术的对比 与传统的监督学习方法如深度学习神经网络和支持向量机等相比，SOM提供了一种不同的视角来处理和理解数据。SOM不依赖于标签数据，更专注于揭示数据的内在关系和结构。此外，与主成分分析（PCA）等其他降维技术相比，SOM保留了数据的非线性关系，这在许多复杂数据集的分析中是非常重要的。&#xA;原理 SOM的基本原理是将输入向量映射到一个二维的网格上。每个网格点（神经元）都有一个与输入空间维度相同的权重向量。通过竞争学习，SOM能够调整这些权重向量，使得相似的输入被映射到相近的神经元上。&#xA;竞争阶段： 对于每个输入向量，找到与之最相似（通常是欧氏距离最小）的神经元。 调整阶段： 调整胜出神经元及其邻域内的权重向量，使它们更靠近输入向量。 流程 初始化： 随机初始化神经元的权重向量。&#xA;竞争： 对于每个输入样本，找到最相似的神经元。&#xA;合作： 确定胜出神经元的邻域。&#xA;适应： 调整胜出神经元及其邻域内神经元的权重。&#xA;重复： 重复步骤2-4，直到网络稳定。&#xA;应用场景 数据可视化：将复杂的高维数据集映射到二维空间，以直观的形式展现数据结构。 聚类分析：自动发现数据中的模式和群组。 特征提取：在降维过程中提取数据的关键特征。 异常检测：识别数据集中的异常或离群点。 实际应用案例 在金融领域，SOM被用于信用评分系统，通过分析客户的历史交易数据来预测其信用风险。在生物信息学中，SOM用于分析和分类复杂的基因表达数据。在图像处理领域，SOM用于图像压缩和特征提取，帮助提高图像识别的效率和准确性。&#xA;Python完整示例 import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from sklearn.datasets import load_iris from sklearn.preprocessing import StandardScaler from minisom import MiniSom # 数据加载 data = load_iris() X = data.</description>
    </item>
    <item>
      <title>非线性支持向量机 |机器学习</title>
      <link>https://www.devean.cn/zh/blog/2023/machine-learning-nonlinear-support-vector-machines/</link>
      <pubDate>Sat, 02 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/machine-learning-nonlinear-support-vector-machines/</guid>
      <description>非线性支持向量机（SVM）是一种强大的监督学习算法，用于解决分类和回归问题。它通过使用核技巧将数据映射到高维空间，从而处理非线性关系。在这篇文章中，我们将探讨非线性 SVM 的工作原理、核函数的作用以及如何在实际中应用非线性 SVM。&#xA;核心概念 线性与非线性 SVM 线性 SVM 在处理线性可分数据时效果显著。然而，当数据集呈非线性分布时，线性 SVM 的性能会受限。非线性 SVM 通过核技巧解决了这个问题。&#xA;核技巧（Kernel Trick） 什么是核技巧？ 核技巧是一种通过转换将低维输入空间映射到高维特征空间的方法，它使得非线性特征组合可以被 SVM 以线性方式处理，核技巧由一些数学工具核函数实现。&#xA;核函数定义 核函数是一个数学函数，能够计算数据点在高维特征空间中的内积，而无需直接计算这些特征。换句话说，它可以让我们在原始特征空间中间接地计算在更高维特征空间的内积。&#xA;核函数的作用 维度映射： 核函数通过隐式地将数据映射到一个更高维的空间，帮助处理数据的非线性特征。 计算简化： 直接在高维空间中处理数据是复杂和计算密集的。核函数通过在原始空间中进行计算来避免这个问题，从而简化了计算过程。 处理非线性问题： 在许多实际问题中，数据集无法用线性方法分割。核函数使 SVM 能够通过在高维空间中寻找线性边界来处理这些非线性问题。 常见的核函数 高斯径向基函数（RBF）核： 最常用的核函数，适合处理没有明显特征模式的复杂数据集。 $$K(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma ||\mathbf{x}_i - \mathbf{x}_j||^2)$$ 其中，$\gamma$ 是缩放参数。&#xA;多项式核： 用于将数据映射到由原始特征的多项式组成的高维空间。 $$K(\mathbf{x}_i, \mathbf{x}_j) = (\gamma \mathbf{x}_i \cdot \mathbf{x}_j + r)^d$$&#xA;其中，$\gamma$ 是缩放参数，$d$ 是多项式的度数,$ r $ 是系数项。&#xA;Sigmoid 核： 类似于神经网络的激活函数。&#xA;$$K(\mathbf{x}_i, \mathbf{x}_j) = anh(\gamma \mathbf{x}_i \cdot \mathbf{x}_j + r)$$ 其中，$\gamma$ 是缩放参数，$r$ 是偏置项。</description>
    </item>
    <item>
      <title>支持向量机线性不可分 | 机器学习</title>
      <link>https://www.devean.cn/zh/blog/2023/machine-learning-support-vector-machine-non-linearly-separable/</link>
      <pubDate>Sun, 19 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/machine-learning-support-vector-machine-non-linearly-separable/</guid>
      <description>本文从支持向量机线性不可分、软间隔、松弛变量、目标函数、约束条件、超参数 C,实际应用场景判别线性是否可分等几方面讲概述了支持向量机线性不可分&#xA;线性不可分 SVM 有些时候数据本身存在噪点或异常值、在这种场景下,支持向量机又会如何处理呢,看下图&#xA;在这里，我们在红球的边界中有一个蓝球。那么 SVM 是如何对数据进行分类的呢？这很简单！红色球边界中的蓝色球是蓝色球的异常值。SVM 算法具有忽略异常值并找到使边际最大化的最佳超平面的特点。SVM 对异常值具有鲁棒性。&#xA;在这种类型的数据点中，SVM 所做的就是像之前的数据集一样找到最大边距，并在每次点跨越边距时添加惩罚。因此，此类情况下的边距称为软边距。当数据集存在软边距时，SVM 会尝试最小化(1/margin+∧(Σpenalty))。&#xA;引入松弛变量 首先，引入松弛变量（Slack Variables），这些变量表示数据点到超平面的距离。对于每个数据点，引入一个对应的松弛变量 $\xi_i$，表示第 $i$ 个数据点允许的错误。&#xA;目标函数修改 软间隔的目标函数通过调整传统硬间隔的目标函数，以考虑错误和松弛变量。新的目标函数可以表示为：&#xA;$ \min_{w, b, \xi} \frac{1}{2}||w||^2 + C \sum_{i=1}^{N} \xi_i $&#xA;其中：&#xA;$||w||^2$ 表示模型复杂度，即超平面的法向量的范数。 $\sum_{i=1}^{N} \xi_i$ 表示所有松弛变量的总和。 $C$ 是一个用户定义的超参数，用于平衡最小化模型复杂度和最小化分类错误的目标。&#xA;约束条件调整 随着引入了松弛变量，约束条件也需要相应的调整。约束条件现在变为：&#xA;$ y_i(w \cdot x_i + b) \geq 1 - \xi_i, \quad \text{for } i = 1, 2, \ldots, N $&#xA;这确保了即使数据点落在错误的一侧，它们的函数间隔仍然至少为 $1 - \xi_i$。&#xA;超参数调整 软间隔的效果受到超参数 $C$ 的影响， $C$ 的选择取决于对模型性能的需求。较大的 $C$ 值会更强调正确分类，但可能导致过拟合，而较小的 $C$ 值会更注重找到更大间隔，但可能容忍更多的错误分类。通过在实际问题中调整 $C$ 的值，可以根据具体情况平衡模型的复杂性和对错误的容忍度。这种灵活性使得软间隔成为处理线性不可分数据的有力工具。</description>
    </item>
    <item>
      <title>支持向量机线性可分 | 机器学习</title>
      <link>https://www.devean.cn/zh/blog/2023/machine-learning-support-vector-machine-linearly-separable/</link>
      <pubDate>Sat, 18 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/machine-learning-support-vector-machine-linearly-separable/</guid>
      <description>本文从支持向量机概念、硬间隔、软间隔和非线性的区别、原理、术语、最大间隔数学推导几个方面详细讲解线性可分的支持向量机。&#xA;基础概念 支持向量机(Support Vector Machine)SVM，是一种监督学习模型，适用于二分类任务。SVM 算法的主要目标是在 N 维空间中找到能够将特征空间中不同类的数据点分开的最优超平面。超平面尝试使不同类的最近点之间的间隔尽可能最大。超平面的维度取决于特征的数量。如果输入特征的数量是两个，那么超平面只是一条线。如果输入特征的数量为三个，则超平面变为二维平面。当特征数量超过三个时就变得难以想象。&#xA;硬间隔、软间隔和非线性SVM区别 硬间隔数据是完全准确可分的、不存在分类错误的情况，软间隔是允许一定量的样本分类错误、而线性不可分是线性公式无解，只能使用非线性方式求解的&#xA;线性可分 SVM 即假设样本数据是线性可分离的情况下，我们直接使用线性 SVM 对数据进行分类。基本原理是找到一个超平面，将数据划分为两个类，使得类别之间的间隔最大化。&#xA;定义 给定训练样本集 D={(x1,y1)，(x2,y2)，&amp;hellip;，(xm,ym)},yi∈{-1,+1}，分类学习最基本的想法就是基于训练集 D 在样本空间中找到一个划分超平面，将不同类别的样本分开。下面列子以二维数据展开、实际生活中多维数据与二维几乎无差别，只是数据特征维度变为了多维。&#xA;直观上看，应该去找位于两类训练样本“正中间”的划分超平面，即图中红色的那个，因为该划分超平面对训练样本局部扰动的“容忍”性最好。如果，由于训练集的局限性或噪声的因素，训练集外的样本可能比图中的训练样本更接近两个类的分隔界，这将使许多划分超平面出现错误，而红色的超平面受影响最小。&#xA;要找到最佳超平面,即得找到样本数据点离超平面最近的点的距离最大化，从上面两个图中可以看出,离图中红线最近的点即被圈住的样本到红色超平面距离最大。其中 w=(w1;w2;&amp;hellip;;wd)为法向量，决定了超平面的方向；b 为位移项，决定了超平面与原点之间的距离。&#xA;术语 向量距离：即上图中任何一个样本点到红色超平面的距离 $$r= \frac {w^Tx+b} {||w||}$$&#xA;支持向量（support vector）：即图中圈中的样本,支持向量是距离超平面最近的数据点，在决定超平面和边距方面起着关键作用。&#xA;决策边界:即上图中红色超平面,用于分隔特征空间中不同类的数据点。在线性分类的情况下，它将是一个线性方程 $$w^Tx+b=0$$&#xA;上边界：将超平面放大 n 背后&#xA;$$w^Tx+b=1$$&#xA;下边界： $$w^Tx+b=-1$$&#xA;间隔(margin)：即如图上下边界之间的距离&#xA;$$\lambda=\frac {2} {||w||}$$&#xA;求解线性 SVM 决策超平面 1. 列出知超平面方程组 $$w^Tx+b=0$$ $$w^Tx+b=1$$ $$w^Tx+b=-1$$&#xA;2 假设正负超平面向量 假设正决策超平面上的存在点 $x_m$、负决策超平面上存在点 $x_n$, 求两点之间的向量可如下图&#xA;3.可将正负超平面上的向量带入方程计算&#xA;$$\vec w_m \vec x+b=1$$ $$\vec w_n \vec x+b=-1$$&#xA;$$\vec {w} \cdot (\vec x_m- \vec x_n)=2$$</description>
    </item>
    <item>
      <title>什么是套利 | 翻译</title>
      <link>https://www.devean.cn/zh/blog/2023/what-is-arbitrage/</link>
      <pubDate>Wed, 15 Nov 2023 22:59:31 +0800</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/what-is-arbitrage/</guid>
      <description>本文简单科普了什么是套利、有哪些套利方法、套利失效的原因。&#xA;什么是套利 套利是指在无风险回报率之外获得确定的利润。 用量化金融的语言来说，我们 可以说套利机会是今天价值为零但未来价值为正的投资组合 的概率，并且未来为负值的概率为零。&#xA;市场上不存在套利机会的假设是经典金融理论的基础。这个想法是俗话说“天下没有免费的午餐”。&#xA;现在我们可以看到，我们可以想到几种套利方式。以下是最重要的几种套利的列表和说明。&#xA;静态套利是一种无需重新平衡正向持仓的套利。 动态套利是一种需要在未来进行交易的价差套利策略，通常取决于市场状况。 统计套利并非套利，而只是根据过去的统计数据预测，可能获得超过无风险收益的利润（甚至可能根据承担的风险进行适当调整）。 模型无关套利是一种不依赖于任何金融工具数学模型而发挥作用的套利。例如，可利用的对看跌期权平价的违反或对债券与掉期之间关系的违反 依赖于模型的套利需要一个模型。例如，由于不正确的波动率估计，期权定价错误。为了从套利中获利，你需要delta对冲，这需要一个模型。 这有几个套利失效的原因&#xA;报价错误或不可交易 期权价格和股票价格没有同步报价 存在您未计算在内的竞价价差 你的模型是错误的，或者存在你没有考虑到的风险因素 最后我们可以可看下百度百科对于套利 的定义&#xA;[1] Wilmott，M 2009 Frequently Asked Questions In Quantitative Finance, second edition. John Wiley &amp;amp; Sons,Ltd.&#xA;欢迎扫码关注公众号，订阅更多文章!</description>
    </item>
    <item>
      <title>量化金融中的数学应用 | 翻译</title>
      <link>https://www.devean.cn/zh/blog/2023/mathematical-applications-in-quantitative-finance/</link>
      <pubDate>Tue, 14 Nov 2023 22:59:31 +0800</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/mathematical-applications-in-quantitative-finance/</guid>
      <description>本文量从量化金融中数学的应用、常见的建模方法、常见的数学工具普及了量化金融中的应用。&#xA;量化金融中有哪些不同类型的数学？ 在数量金融中使用最多的数学领域是概率论和微分方程。当然，通常需要数值方法来生成数字。&#xA;这里列出了各种建模方法和一些有用的工具。“建模方法”和“工具”之间的区别将开始变得清晰。&#xA;建模方法&#xA;概率模型 决策模型 离散：差分方程 连续：微分方程 实用工具&#xA;模拟 离散化方法 近似值 渐进分析 级数解 格林函数 虽然这些清单并非完全是任意列出的，但可以接受一些批评或补充。让我们先来看看建模方法。&#xA;[1] Wilmott，M 2009 Frequently Asked Questions In Quantitative Finance, second edition. John Wiley &amp;amp; Sons,Ltd.</description>
    </item>
    <item>
      <title>K均值聚类(KMC) | 机器学习</title>
      <link>https://www.devean.cn/zh/blog/2023/machine-learning-k-means-clustering/</link>
      <pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/machine-learning-k-means-clustering/</guid>
      <description>本文从概念、应用场景、原理、工作流程、优缺点、应用实践、代码、可视化等几方面诠释 K 均值聚类模型&#xA;概述 K-Means 是一种无监督的聚类算法，其目的是将 n 个数据点分为 k 个聚类。每个聚类都有一个质心，这些质心最小化了其内部数据点与质心之间的距离。&#xA;它能做什么 市场细分: 识别具有相似属性的潜在客户群体。 图像分析: 图像压缩和图像分割中的像素聚类。 异常检测: 通过标识不符合标准集群特征的观测结果来检测异常。 基因表达数据分析: 对基因进行聚类以识别具有相似表达模式的基因家族。 原理 初始化： 随机选择 k 个数据点作为初始聚类中心，这些可以是数据集中实际存在的点，也可以是随机生成的点。&#xA;K-Means++: 为了避免随机初始化可能导致的不良结果，K-Means++ 策略通过特别选择远离其他中心的起始中心来优化初始聚类中心的位置。 分配： 遍历样本数据集，计算每个数据点到每个质心的距离，找出数据点距离最近的质心，将数据点分配给该聚类。&#xA;公式&#xA;设 $c_i$ 是第 i 个集群， $ \mu_i$ 是第 i 个集群的中心，目标是最小化所有数据点和其所在集群中心之间的平方距离之和： $ D = \sum_{i=1}^{K} \sum_{x \in c_i} ||x - \mu_i||^2 $&#xA;$d(p, q) = \sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \cdots + (p_n - q_n)^2}$&#xA;更新： 计算每个聚类内的平均值，并将平均值设为新的聚类中心。</description>
    </item>
    <item>
      <title>机器学习特征缩放</title>
      <link>https://www.devean.cn/zh/blog/2023/machine-learning-feature-scaling/</link>
      <pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/machine-learning-feature-scaling/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文从特征缩放概念、目的、常用特征缩放方法：最小-最大缩放、标准缩放、鲁棒缩放、L2 Normalization、L1 Normalization、Power Transformer的公式讲解、Python缩放数据可视化对比诠释了特征缩放&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;什么是特征缩放&#34;&gt;什么是特征缩放&lt;/h2&gt;&#xA;&lt;p&gt;特征缩放又称归一化，是机器学习中的一种技术，涉及调整数值数据的量度，使所有数据点在相似的尺度上。例如：身高、体重、年龄、收入等个人特征数据，每个维度的区间不一样，为保证所有维度的特征数据尺度一样，我们就需要对原始数据做特征缩放，将身高、体重、年龄、收入都转化为区间[0,1]之间的数据。&lt;/p&gt;</description>
    </item>
    <item>
      <title>K临近(KNN) | 机器学习</title>
      <link>https://www.devean.cn/zh/blog/2023/machine-learning-k-nearest-neighbours/</link>
      <pubDate>Sun, 10 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/machine-learning-k-nearest-neighbours/</guid>
      <description>本文从概念、原理、距离函数、K 值选择、K 值影响、、优缺点、应用几方面详细讲述了 KNN 算法。&#xA;K 近临(K Nearest-Neighbours) 一种简单的监督学习算法，惰性学习算法，在技术上并不训练模型来预测。适用于分类和回归任务。它的核心思想是：相似的对象彼此接近。例如，若果你想分类一个新的数据点(绿点)，可以查看训练数据中哪些数据点与它最接近，并根据这些最接近的数据点和标签来预测它的标签(红点或蓝圆)。&#xA;概念 K: 这是一个用户指定的正整数，即训练数据分类数量，代表要考虑的最近邻居的数量，上图中假设 K=2,即训练数据分类为蓝色圆和红色三角两类标签。&#xA;距离函数: 用于计算数据点之间的距离。最常见的是欧几里得距离、曼哈顿距离、马氏距离等。&#xA;投票机制:&#xA;分类任务: 将根据 k 个最近邻的多数投票来确定新数据点的类别。 回归任务: 通常取 k 个最近邻的输出变量的平均值。 原理 距离计算： 对于给定的新数据点，计算它与训练数据集中每个点的距离。 选取 K 个邻居： 从训练数据集中选取距离最近的 K 个点。 投票 (对于分类)： 对于 K 个邻居，看哪个类别最为常见，并将其指定为新数据点的类别。 均值 (对于回归)： 对于 K 个邻居，计算其属性的平均值，并将其指定为新数据点的值。 距离度量 欧几里得距离 (Euclidean Distance) 欧几里得距离的名称来源于古希腊数学家欧几里得，是衡量两点在平面或更高维空间中的&amp;quot;直线&amp;quot;距离。它基于勾股定理，用于计算两点之间的最短距离。在日常生活中，我们经常无意识地使用欧几里得距离，例如，当我们说两地之间的&amp;quot;直线&amp;quot;距离时，实际上是在引用欧几里得距离。 公式: 给定两点 P 和 Q，其坐标分别为 $P(x_1, x_2, &amp;hellip;, x_n)$ 和 $Q(y_1, y_2, &amp;hellip;, y_n)$ 在一个 n 维空间中，它们之间的欧几里得距离 d 定义为：&#xA;$d(P, Q) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}$</description>
    </item>
    <item>
      <title>机器学习基础概念</title>
      <link>https://www.devean.cn/zh/blog/2023/machine-learning-basic-concepts/</link>
      <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/machine-learning-basic-concepts/</guid>
      <description>本文从机器学习与传统建模区别、机器学习分类：监督、非监督、半监督、强化，基础算法：K临近(KNN)、K均值(KMC)、朴素贝叶斯(NBC)、支持向量机(SVM)、回归、自组织映射、神经网络原理(NLP)&#xA;什么是机器学习 机器学习是人工智能的一个分支,它让计算机从数据中自动“学”到知识,并用这些知识做决策或预测,而不需要我们一步步明确地告诉它怎么做。&#xA;传统数学 vs 机器学习 数学建模 机器学习 相同点 数据驱动: 两者都利用数据来构建和验证模型。&#xA;预测和推断: 数学建模和机器学习都可以用于预测未知的输出或解释数据中的模式。&#xA;优化问题: 在某些情况下，两者都可能涉及到优化问题，例如，寻找最小化误差的参数。&#xA;不同点 目的 数学建模：旨在用数学的形式来描述现实世界中的现象或问题，往往为了理解其背后的机制或原理。&#xA;主要关注的是预测和泛化。机器学习模型可能不太关心背后的机制，而是关心在未知数据上的性能。&#xA;模型构建 数学建模：模型的形式通常基于对现象的物理、生物或经济学的理解。例如，描述人口增长的模型可能基于出生率和死亡率的估计。&#xA;机器学习：模型的形式主要基于数据。使用的模型可能没有明确的现实意义，例如深度学习模型。&#xA;验证 数学建模：模型的验证通常基于其是否与现实世界的观察相符合，以及其是否可以提供洞察力。&#xA;机器学习：验证通常基于模型在独立测试集上的性能。&#xA;模型的解释性 数学建模：模型往往更具解释性，因为它们是基于现象的某些已知原理或规律构建的。&#xA;机器学习：尤其是某些复杂的模型，如深度神经网络，可能难以解释。尽管如此，机器学习领域也有许多工作在努力提高模型的可解释性。&#xA;应用 数学建模：常应用于工程、物理学、经济学等领域，以帮助专家了解和控制系统。&#xA;机器学习：广泛应用于计算机视觉、自然语言处理、推荐系统等领域，主要关注自动化和预测。&#xA;模型复杂性 数学建模：往往倾向于使用更简单的、基于物理学或其他学科原理的模型。&#xA;机器学习：可能使用非常复杂的模型，特别是当数据量大且复杂度高时。&#xA;总的来说，数学建模和机器学习都是理解、解释和预测现象的工具，但它们的关注点、方法和应用有所不同。&#xA;主要类别 机器学习主要分为三大类：监督学习、非监督学习、强化学习，而监督学习和非监督学习中又衍生出半监督学习。&#xA;监督学习 Supervised Learning是机器学习的一种方法，其模型是通过输入-输出(有标签的数据)对进行训练，目标是从给定的数据中学习一个映射函数,以便在给定新的输入时，模型可以预测相应的输出 。训练过程涉及到输入数据和其相应的标签，并尝试找到这两者之间的关系。一旦模型被训练，它可以用来预测新、未标签数据的输出。&#xA;非监督学习 Unsupervised Learning模型被训练在没有标签的数据上。它的目的是学习数据的底层结构、分布或表示，而不是预测标签。与监督学习不同，非监督学习的目标并不是预测一个输出。相反，它试图通过某种方式学习数据的结构，这可以是通过聚类、降维或生成模型等方式来实现的。&#xA;强化学习 Reinforcement Learning是通过与环境交互来学习如何行动，从而最大化某种定义的长期回报。与传统的监督学习不同，强化学习通常涉及决策问题，其中每个行动都会影响未来的回报。&#xA;半监督学习 Semi-supervised Learning是介于两个极端之间(监督式是指整个数据集被标记，而非监督式是指没有标记)。半监督学习任务具有一个标记和一个未标记的数据集。它使用未标记的数据来获得对数据结构的更多理解。通常，SSL使用小的带标签数据集和较大的未带标签数据集来进行学习。)学习正如其名称所示，介于两个极端之间(监督式是指整个数据集被标记，而非监督式是指没有标记)。半监督学习任务具有一个标记和一个未标记的数据集。它使用未标记的数据来获得对数据结构的更多理解。通常，SSL使用小的带标签数据集和较大的未带标签数据集来进行学习。&#xA;为什么会用半监督学习 半监督学习位于监督学习和非监督学习之间，利用少量的标记数据和大量的未标记数据进行学习。以下是为什么要使用半监督学习的原因：&#xA;数据标注成本高 ：在很多应用中，收集大量数据是相对容易的，但为这些数据打标签则既昂贵又耗时。例如，在医学图像领域，一个专家可能需要花费大量时间来手动标注图像中的特定结构或病变。利用半监督学习，可以用少量的标注数据和大量的未标注数据共同训练模型。&#xA;利用数据的完整潜力 ：未标记的数据包含有关数据分布的有用信息。半监督学习方法尝试利用这些信息来改善模型的性能。&#xA;提高泛化能力 ：在某些情况下，利用大量的未标记数据可以帮助模型更好地泛化到新的、未见过的数据。&#xA;数据标注可能存在误差 ：在某些场景中，即使数据被标注，标签也可能存在噪音或误差。在这种情况下，使用半监督学习方法，结合大量的未标记数据，可能会提供一个更稳健的学习策略。&#xA;在某些任务中，有很多相关的未标记数据 ：例如，在自然语言处理中，我们可能有少量标记的数据集，但可以从网络上轻松获得大量的相关文本。半监督学习可以利用这些未标记的文本来提高模型的性能。&#xA;适应数据的变化 ：在动态环境中，数据分布可能随时间而变化。利用半监督学习，可以定期利用新收集的未标记数据来更新模型，使其适应变化。&#xA;总之，半监督学习提供了一种在有限标记数据的情况下利用未标记数据的方法，这对于许多实际应用来说是非常有价值的。&#xA;模型 K近临 K Nearest-Neighbours是一种监督学习技术，给定一个新的观测值，KNN算法会从训练数据集中搜索出k个与其最相似的实例，然后基于这些邻居的属性来预测新观测值的标签。</description>
    </item>
    <item>
      <title>环新疆摩旅</title>
      <link>https://www.devean.cn/zh/blog/2023/motorcycle-tour-around-xinjiang/</link>
      <pubDate>Wed, 02 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2023/motorcycle-tour-around-xinjiang/</guid>
      <description>环新疆摩旅 版权声明：以下图片版权归本人所有，禁止一切商用，如需商用请与本人取得联系获取授权，侵权必究！ 2023.8.2 北京&amp;ndash;巴彦淖尔临河服务区 2023.8.3 巴彦淖尔临河服务区&amp;ndash;额济纳旗 2023.8.3 额济纳旗&amp;ndash;哈密 2023.8.5 哈密-巴里坤 阿勒吞古街 哈密文化馆 哈密回王墓 天山庙 巴里坤草原 2023.8.6 巴里坤-吐鲁番-乌鲁木齐 巴里坤糊 天山无人区峡谷 吐峪沟麻扎村 2023.8.7 乌鲁木齐 2023.8.8 阿勒泰五彩湾 2023.8.9 可可托海 2023.8.10 禾木 2023.8.11-12 喀纳斯 2023.8.13 吉木乃 草原石城 吉木乃草原 松海湾 2023.8.16 塞里湖&amp;ndash;尼勒克 赛里木湖&amp;ndash;大西洋的最后一滴泪 果子沟大桥 2023.8.17 尼勒克&amp;ndash;奎屯 特克斯八卦城 2023.8.19 奎屯&amp;ndash;独库640兰萨德克服务区 安集海大峡谷 2023.8.20 独库640兰萨德克服务区&amp;ndash;天山神秘大峡谷 </description>
    </item>
    <item>
      <title>关于我</title>
      <link>https://www.devean.cn/zh/page/about/</link>
      <pubDate>Thu, 15 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/page/about/</guid>
      <description>关于我</description>
    </item>
    <item>
      <title>并发与多线程</title>
      <link>https://www.devean.cn/zh/blog/2019/concurrency-and-multithread/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2019/concurrency-and-multithread/</guid>
      <description>并发与多线程 1 常见概念 1.1 操作系统线程运行状态 NEW RUNNABLE RUNNING BLOCKED 1.2 Java虚拟机线程实际运行状态 public enum State { NEW 尚未开始的线程处于此状态，即刚创建线程对象，未调用start()方法 RUNNABLE 新建线程调用start()方法后，在Java虚拟机中执行的线程处于此状态，但它可能正在等待来自操作系统的其他资源（如处理器）。 BLOCKED 处于阻塞状态的线程正在等待监视器锁定进入同步块或同步方法，或者重入锁进入同步块或同步方法 后调用Object.wait()方法 WAITING 由于调用以下方法之一，线程处于等待状态 Object.wait(); 无超时 Thread.join(); 无超时 LockSupport.park(); 例如，a.在对象上调用Object.wait（）的线程正在等待另一个线程调用Object.notify（）或Object.notifyAll（）在该对象。 b.一个名为Thread.join（的线程正在等待指定的线程终止。 TIMED_WAITING 由于调用一个线程，线程处于定时等待状态,使线程处于定时等待状态可调用方法如下： Thread.sleep(long); Object.wait(long) Thread.join(long); LockSupport.parkNanos(long); LockSupport.parkUntil(long); TERMINATED 终止线程的线程状态。 即线程已完成当前任务的执行。 } 1.3 重入锁 概念： 一个线程试图获得它自己持有的锁，那么这个请求就会成功 实现原理： 1.为每个锁绑定所有者和计数值,每重入一次该计数值自增1，而当线程每退出一次计数值递减，直到计数值为零才释放锁。 常用实现 1.4 sychroinzed 概述： 在JDK1.6之前被称为重量级锁，然后在JDK1.6中为了减少获得和释放锁所带来的性能消耗引入了偏量锁和轻量级锁 实现原理： 互斥同步原理，JVM规范中都是给予进入和对出Monitor对象来实现方法同步和代码块同步的，但两者的实现细节不同: 代码块同步是使用monitorenter和monitorexit指令实现的 使用分类 按目标分类：类锁和对象锁&#xA;按范围分类：方法和代码块&#xA;使用形式： 普通方法+syncronized 锁是当前实例对象&#xA;public class InstanceObjectSyncronizedTest{ private Integer num = 5; public syncronized Integer getNum(){ num++ return num; } } 静态方法+syncronized 锁是当前类的Class对象</description>
    </item>
    <item>
      <title>负载均衡</title>
      <link>https://www.devean.cn/zh/blog/2019/load-balance/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2019/load-balance/</guid>
      <description>高性能负载均衡 架构设计ProcessOn 负载均衡分类 DNS负载均衡 优点&#xA;1.简单、成本低 2.就近访问，提升访问速度 缺点&#xA;1.更新不及时 2.拓展性差 3.分配策略简单 硬件负载均衡 F5&#xA;性能(200-800W/S) A10&#xA;优点&#xA;功能强大 性能强大 稳定性高 支持安全防护 缺点&#xA;价格昂贵 拓展能力差 软件负载均衡 Nginx(7层负载均衡)&#xA;性能（5W/S） LVS（四层负载均衡)&#xA;性能（10-80W/S） 优点&#xA;简单 便宜 灵活 缺点&#xA;性能一般 不具备安全防护 功能不够强大 典型负载均衡架构 案例1 dns地理级别负载均衡 硬件本地多集群级别负载均衡 软件集群内机器级负载均衡 算法分类 任务平分类 轮询&#xA;无需关注服务器负载、性能等状态 只关注服务是否宕机 加权轮询&#xA;根据服务器权重进行任务分配 无法根据服务器状态差异进行任务分配 负载均衡类 根据任务场景和业务场景的不同指标衡量&#xA;四层LVS网络设备中的连接数 七层Nginx中的HTTP请求数 CPU密集型系统按CPU负载 I/O密集型系统按I/O负载 难点&#xA;指标的收集及统计 性能最优类 以服务器的角度来分配&#xA;需采样收集每个服务器上任务的响应时间 难点&#xA;采样周期确定 采样关键业务 hash类 源地址 Hash ID的Hash </description>
    </item>
    <item>
      <title>架构设计</title>
      <link>https://www.devean.cn/zh/blog/2019/arch-design/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/blog/2019/arch-design/</guid>
      <description>架构设计 架构设计ProcessOn 三原则 合适原则 合适优于业界领先 简单原则 简单优于复杂 演化原则 演化优于一步到位 基本问题 高可靠 可拓展 高性能 复杂度来源 高性能 常见方案&#xA;水平拓展(负载均衡)&#xA;单个业务横向加机器水平拓展&#xA;注意状态或竞争资源 垂直拓展&#xA;单机硬件性能提升&#xA;业务模块垂直拆分&#xA;注意拆分粒度&#xA;粒度过下会导致接口间调用指数级增长 衡量&#xA;QPS TPS 高可用 冗余拓展&#xA;分类&#xA;存储高可用 计算高可用 状态决策&#xA;独裁式&#xA;决策者收集上报者的信息然后决策 协商式&#xA;主备模式 民主式&#xA;选举模式 常见方案&#xA;主备方案 集群方案 可拓展性 预测变化 应对变化 低成本 安全 规模 步骤 识别复杂度 复杂度&#xA;高可用 可拓展 高性能 需要解决的复杂度只可能是其中一两点&#xA;设计备选方案 评估和选择备选方案 方案质量属性&#xA;性能 可用性 硬件成本 项目投入 复杂度 安全性 可拓展性 版本兼容性 为每个方案质量属性赋值权重&#xA;详细方案设计 负载均衡方式&#xA;库表设计</description>
    </item>
    <item>
      <title></title>
      <link>https://www.devean.cn/zh/page/my-first-post/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/zh/page/my-first-post/</guid>
      <description></description>
    </item>
  </channel>
</rss>
