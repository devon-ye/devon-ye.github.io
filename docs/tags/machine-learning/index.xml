<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on 德文的博客</title>
    <link>https://www.devean.cn/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on 德文的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 02 Dec 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.devean.cn/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>机器学习 | 非线性支持向量机</title>
      <link>https://www.devean.cn/post/2023-12-02-machine-learning-nonlinear-support-vector-machines/</link>
      <pubDate>Sat, 02 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/post/2023-12-02-machine-learning-nonlinear-support-vector-machines/</guid>
      <description>非线性支持向量机（SVM）是一种强大的监督学习算法，用于解决分类和回归问题。它通过使用核技巧将数据映射到高维空间，从而处理非线性关系。在这篇</description>
    </item>
    <item>
      <title>机器学习 | 支持向量机线性不可分</title>
      <link>https://www.devean.cn/post/2023-11-19-machine-learning-support-vector-machine-non-linearly-separable/</link>
      <pubDate>Sun, 19 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/post/2023-11-19-machine-learning-support-vector-machine-non-linearly-separable/</guid>
      <description>本文从支持向量机线性不可分、软间隔、松弛变量、目标函数、约束条件、超参数 C,实际应用场景判别线性是否可分等几方面讲概述了支持向量机线性不可分</description>
    </item>
    <item>
      <title>机器学习 | 支持向量机线性可分</title>
      <link>https://www.devean.cn/post/2023-11-18-machine-learning-support-vector-machine-linearly-separable/</link>
      <pubDate>Sat, 18 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/post/2023-11-18-machine-learning-support-vector-machine-linearly-separable/</guid>
      <description>本文从支持向量机概念、硬间隔、软间隔和非线性的区别、原理、术语、最大间隔数学推导几个方面详细讲解线性可分的支持向量机。 基础概念 支持向量机(S</description>
    </item>
    <item>
      <title>机器学习 | 特征缩放</title>
      <link>https://www.devean.cn/post/2023-11-11-machine-learning-feature-scaling/</link>
      <pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/post/2023-11-11-machine-learning-feature-scaling/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本文从特征缩放概念、目的、常用特征缩放方法：最小-最大缩放、标准缩放、鲁棒缩放、L2 Normalization、L1 Normalization、Power Transformer的公式讲解、Python缩放数据可视化对比诠释了特征缩放&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;什么是特征缩放&#34;&gt;什么是特征缩放&lt;/h2&gt;
&lt;p&gt;特征缩放又称归一化，是机器学习中的一种技术，涉及调整数值数据的量度，使所有数据点在相似的尺度上。例如：身高、体重、年龄、收入等个人特征数据，每个维度的区间不一样，为保证所有维度的特征数据尺度一样，我们就需要对原始数据做特征缩放，将身高、体重、年龄、收入都转化为区间[0,1]之间的数据。&lt;/p&gt;</description>
    </item>
    <item>
      <title>K临近(KNN) | 机器学习</title>
      <link>https://www.devean.cn/post/2023-11-12-machine-learning-k-nearest-neighbours/</link>
      <pubDate>Sun, 10 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/post/2023-11-12-machine-learning-k-nearest-neighbours/</guid>
      <description>本文从概念、原理、距离函数、K 值选择、K 值影响、、优缺点、应用几方面详细讲述了 KNN 算法。 K 近临(K Nearest-Neighbours) 一种简单的监督学习算法，惰性学习算法，在技</description>
    </item>
    <item>
      <title>机器学习 | 基础概念</title>
      <link>https://www.devean.cn/post/2023-09-08-machine-learning-basic-concepts/</link>
      <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://www.devean.cn/post/2023-09-08-machine-learning-basic-concepts/</guid>
      <description>本文从机器学习与传统建模区别、机器学习分类：监督、非监督、半监督、强化，基础算法：K临近(KNN)、K均值(KMC)、朴素贝叶斯(NBC)、</description>
    </item>
  </channel>
</rss>
